{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-11-06-ajtfb-chapter-1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKuzCP+nwPasbiOKgHHYrc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJL4-Qwluy4"
      },
      "source": [
        "# \"A Journey Through Fastbook (AJTFB) - Chapter 2\"\n",
        "> \"The second in a weekly-ish series where I revisit the fast.ai book, [\\\"Deep Learning for Coders with fastai & PyTorch\\\"](https://github.com/fastai/fastbook), and provide commentary on the bits that jumped out to me chapter by chapter.  So without further adieu, let's go!\"\n",
        "\n",
        "- toc: false\n",
        "- branch: master\n",
        "- badges: true\n",
        "- hide_binder_badge: true\n",
        "- comments: true\n",
        "- author: Wayde Gilliam\n",
        "- categories: [fastai, fastbook]\n",
        "- image: images/articles/fastbook.jpg\n",
        "- hide: true\n",
        "- search_exclude: true\n",
        "- permalink: temp-posts/ajtfb-chapter-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfcRNESotGLU"
      },
      "source": [
        "Other posts in this series:\n",
        "[A Journey Through Fastbook (AJTFB) - Chapter 1](https://ohmeow.com/posts/2020/11/06/_11_06_ajtfb_chapter_1.html)\n",
        "\n",
        "## Chapter 2\n",
        "\n",
        "---\n",
        "### Starting Your Project\n",
        "\n",
        "#### Things to think about when deciding on project feasibility\n",
        "\n",
        "> the most important consideration is data availability\n",
        "\n",
        "If you don't have enough quality data and/or the means to create it ... good luck.\n",
        "\n",
        "> Important: Consider that **data augmentation** can alleviate both the need for more manual labelling and also protect you from problems with out-of-domain data (e.g. \"when unexpected image types arise in the data when the model is being used in production\") by synthetically creating more data likely to be seen that may not be in your dataset as is.\n",
        "\n",
        "> Important: Start with a smaller ResNet (like 18 or 34) and move up as needed.\n",
        "\n",
        "\n",
        "\n",
        "> iterate from end to end in your project: don't spend months fine-tuning your model, or polishing the perfect GUI, or labeling the perfect dataset.\n",
        "\n",
        "In other words, fail early and fail often. If you don't, you're likely to only uncover critical problems much later than you would have before, and even worse, you're likely to not produce anything at all! In the world of deep learning there are a number of tools, that while helpful, can really get you so bogged down that you never deploy something usable (e.g., experiment tracking tools, hyperparameter optimization libraries, etc...). Also, remember that getting something in production is a different task from winning a kaggle competition, where the later may require use of some of those aforementioned tools and the ensembling of dozens of models. For production, something better than human is often good enough to get out there and through refactoring, improve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x904qZCHHcb"
      },
      "source": [
        "---\n",
        "## The Drivetrain Approach\n",
        "\n",
        "![](https://raw.githubusercontent.com/fastai/fastbook/41a60e44d588139a03452f1907359fc2322f8d5f/images/drivetrain-approach.png)\n",
        "\n",
        "### Steps 1-3\n",
        "\n",
        "### Step 4\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o_gV79MDqoR"
      },
      "source": [
        "---\n",
        "### Metrics\n",
        "\n",
        "**Metrics** are a human-understandable measures of model quality whereas the **loss** is the machine's.  They are based on your validation set and are what you really care about, whereas the loss is \"a measure of performance\" that the training system can use to update weights automatically.\n",
        "\n",
        "A good choice for loss is a function \"that is easy for ***stochastic gradient descent (SGD)*** to use, whereas a good choies for your metrics are functions that your business users will care about. Seldom are they the same because most metrics don't provide smooth gradients that SGD can use to update your model's weights.\n",
        "\n",
        "Examples of common metrics:\n",
        "\n",
        "**error rate** = \"the proportion of images that were incorrectly identified.\n",
        "\n",
        "**accuracy** = the proportation of images that were correctly identified (`1 - error rate`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1jmyUejDxmE"
      },
      "source": [
        "---\n",
        "## Validation & Test Sets\n",
        "\n",
        "### What is a validation set?\n",
        "\n",
        "A ***validation set*** (also know as the \"development set\") does not include any data from the ***training set***.  It's purpose to is gauge the generalization prowess of your model and also ensure you are neight overfitting or underfitting.\n",
        "\n",
        "> If [the model] makes an accurate prediction for a data item, that should be because it has learned characteristics\n",
        "> of that kind of item, and not because the model has been shaped by *actually having seen that particular\n",
        "> item*.\n",
        "\n",
        "### Why do we need a validation set?\n",
        "\n",
        "> [because] what we care about is how well our model works on *previously unseen images* ... the longer\n",
        "> you train for, the better your accuracy will get on the training set ... as the model starts to memorize\n",
        "> the training set rather than finding generalizable underlying patterns in the data = **overfitting**\n",
        "\n",
        "![](https://raw.githubusercontent.com/fastai/fastbook/41a60e44d588139a03452f1907359fc2322f8d5f/images/att_00000.png)\n",
        "\n",
        "***Overfitting*** happens when the model \"remembers specific features of the input data, rather than generalizing well to data not seen during training.\"\n",
        "\n",
        "> Important: Your models should always overfit before anything else.  It is your training loss gets better while your validation loss gets worse ... in other words, if you're validation loss is improving, even if not to the extent of your training loss, you are *not* overfitting\n",
        "\n",
        "> Important: ALWAYS include a validation set.\n",
        "\n",
        "> Important: ALWAYS measure your accuracy (or any metrics) on the validation set.\n",
        "\n",
        "> Important: Set the `seed` parameter so that you \"get the same validation set every time\" so that \"if we change our model and retrain it, we know any differences are due to the changes to the model, not due to having a different random validation set.\"\n",
        "\n",
        "The validation set also informs us how we may change the  ***hyperparamters*** (e.g., model architecture, learning rates, data augmentation, etc...) to improve results.  These parameters are NOT learned ... they are choices WE make that affect the learning of the model parameters.\n",
        "\n",
        "### What is a test set?\n",
        "\n",
        "A ***test set*** ensures that we aren't overfitting our hyperparameter choices; it is held back even from ourselves and used to evaulate the model at the very end.\n",
        "\n",
        "> Important: If evaluating 3rd party solutions know how to create a good test set and how to create a good baseline model.  Hold these out from the potential consultants and use them to fairly evaluate their work.\n",
        "\n",
        "### How do you define a good validation and test sets?\n",
        "\n",
        "See pp.50-54 ...\n",
        "\n",
        "> A key property of the validation and test sets is that they must be representative of the new data\n",
        "> you will see in the future.\n",
        "\n",
        "For time series, that means you'll likely want to make your validation set a continuous section with the latest dates.\n",
        "\n",
        "You'll also want to make sure your model isn't learning particular ancillary features of particular things in your images (e.g., you want to see how your model performs on a person or boat it hasn't seen before ... see pp.53-54 for examples).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd-sBJb-7tAq"
      },
      "source": [
        "---\n",
        "## Q & A & Best Practices\n",
        "\n",
        "### What is a `Transform`\n",
        "\n",
        "> A **Transform** conatins code that is applied automatically during training. There are two kinds ...\n",
        "1. `item_tfms`: Applied to each item\n",
        "2. `batch_tfms`: Applied to a *batch* of items at a time *using the GPU*\n",
        "\n",
        "### Why do we make images 224x224 pixels?\n",
        "> This is the standard size for historical reasons (old pretrained models require this size exactly) ...\n",
        "> If you increase the size, you'll often get a model with better results since it will be able to focus\n",
        "> on more details.\n",
        "\n",
        "> Important: Train on progressively larger image sizes using the weights trained on smaller sizes as a kind of pretrained model.\n",
        "\n",
        "### What is a ResNet & Why use it for computer vision tasks?\n",
        "\n",
        "A **ResNet** is a model architecture that has proven to work well in CV tasks. Several variants exist with different numbers of layers with the larger architectures taking longer to train and more prone to overfitting especially with smaller datasets.\n",
        "\n",
        "> Important: Start with a smaller ResNet (like 18 or 34) and move up as needed.\n",
        "\n",
        "> Important: If you have a lot of data, the bigger resnets will likely give you better results.\n",
        "\n",
        "And what other things can use images recognizers for besides image tasks? Sound, time series, malware classification ...\n",
        "\n",
        "> ... a good rule of thumb for converting a dataset into an image representation: if the human eye can recognize categories from the images, then a deep learning model should be able to do so too.\n",
        "\n",
        "See pp.36-39\n",
        "\n",
        "### How can we see what our NN's are actually learning/doing?\n",
        "\n",
        "See pp.33-36. Being able to inspect what your NN is doing (e.g., looking at the activations and the gradients) is one of the most important things you can learn as they are often the key to improving results.\n",
        "\n",
        "> Important: Learn how to visualize and understand your activations and gradients!\n",
        "\n",
        "### What is the difference between categorical and continuous datatypes?\n",
        "\n",
        "***Categorical*** data \"contains values taht are one of a discrete set of choice\" such as gender, occupation, day of week, etc...\n",
        "\n",
        "***Continuous*** data is numerical that represents a quantity such as age, salary, prices, etc...\n",
        "\n",
        "> Important: For tasks that predict a continuous number, consider using `y_range` to constrain the network to predicting a value in the known range of valid values. (see p.47)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSwEOzDpHHBj"
      },
      "source": [
        "---\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. https://book.fast.ai - The book's website; it's updated regularly with new content and recommendations from everything to GPUs to use, how to run things locally and on the cloud, etc...\n",
        "\n",
        "2. https://course.fast.ai/datasets - A variety of slimmed down datasets you can use for various DL tasks that support \"rapid prototyping and experimentation.\" \n",
        "\n",
        "3. https://huggingface.co/docs/datasets/ - Serves a similar purpose to the fastai datasets but for the NLP domain. Includes metrics and full/sub-set datasets that you can use to benchmark your results against the top guns of deep learning.\n",
        "\n",
        "\n",
        "> Important: Start with a smaller dataset and scale up to full size to accelerate modeling!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2wEfmj5CLA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}